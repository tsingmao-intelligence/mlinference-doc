# ğŸ‡ å¿«é€Ÿå¼€å§‹

## 0x01 å®‰è£…ä¸è®¤è¯

### è®¤è¯æ–‡ä»¶éƒ¨ç½²

è¯·è”ç³»å‘è¡Œæ–¹è·å¾—ç›¸åº”çš„å®‰è£…åŒ…ï¼Œä»¥åŠè®¤è¯æ–‡ä»¶ã€‚å°†è®¤è¯æ–‡ä»¶certæ”¾å…¥\~/.miæ–‡ä»¶å¤¹ä¸‹ã€‚

### ä¸»ä½“åŒ…å®‰è£…

å°†ä¸‹è½½ä¸‹æ¥çš„å®‰è£…åŒ…è§£å‹è‡³ä»»æ„ä½ç½®ï¼Œå¹¶è®¾ç½®å¥½ç›¸åº”çš„è·¯å¾„

```bash
export PATH=/path/to/package/bin:$PATH
export LD_LIBRARY_PATH=/path/to/package/lib:$LD_LIBRARY_PATH
```

æ¿€æ´»ä¸»æœºä¸­éƒ¨ç½²çš„pythonç¯å¢ƒï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤æ¥å®‰è£…ç›¸åº”çš„whlåŒ…

```sh
# cd to the unzipped package
pip install python/*.whl
```

## 0x02 å¿«é€Ÿæ„å»ºå¤§æ¨¡å‹æœåŠ¡

### æƒé‡è½¬æ¢

MLInferenceæä¾›äº†ä¸€é”®å¯åŠ¨å¤§æ¨¡å‹æœåŠ¡çš„å…¥å£ã€‚é¦–å…ˆéœ€è¦å‡†å¤‡å¥½æ¨¡å‹æƒé‡æ–‡ä»¶ï¼ˆHFæ ¼å¼ï¼‰ï¼Œä¹‹åï¼Œé€šè¿‡å¦‚ä¸‹å‘½ä»¤è¿›è¡Œæƒé‡æ–‡ä»¶çš„æ ¼å¼è½¬æ¢ï¼š

```bash
mkdir -p path/to/out
python -m mi.convert --path /path/to/model --out /path/to/out --tp 1/2/4/8
```

å…¶ä¸­--tpæŒ‡tensorå¹¶è¡Œçš„ç»´åº¦ï¼ŒæŒ‰ç…§éœ€æ±‚æ¥è¿›è¡Œè®¾ç½®ã€‚

### æœåŠ¡å¯åŠ¨

MLInferenceé‡‡ç”¨äº†å‰åç«¯åˆ†ç¦»çš„æ¶æ„è®¾è®¡æ–¹å¼ï¼Œéœ€è¦å•ç‹¬å¯åŠ¨å‰ç«¯æœåŠ¡ï¼ˆå¯¹å¤–æä¾›ä¸Šå±‚è®¿é—®æ¥å£ï¼Œå¦‚chatã€generationç­‰ç­‰æ–¹æ³•ï¼‰ä»¥åŠåç«¯æœåŠ¡ï¼ˆå¯¹å†…çš„å¾®æœåŠ¡æ¶æ„ï¼‰ã€‚é€šè¿‡å¦‚ä¸‹æ–¹å¼å¯åŠ¨åç«¯æœåŠ¡ï¼š

```bash
python -m mi.backend.launch --model /path/to/out --device all --port 12222
```

å…¶ä¸­ï¼Œ--deviceæŒ‡å®šäº†å¯åŠ¨çš„åŠ é€Ÿå™¨æ•°é‡ï¼Œallä¸ºæ‰€æœ‰åŠ é€Ÿå™¨å¯ç”¨ï¼Œä¹Ÿå¯ä»¥æ¢æˆæ•°é‡æŒ‡å®šï¼Œéœ€è¦æ³¨æ„ï¼šåŠ é€Ÿå™¨æ•°é‡éœ€è¦ä¸ºtensorå¹¶è¡Œç»´åº¦çš„æ•´æ•°å€ï¼Œæ¯”å¦‚tp=2ï¼Œåˆ™åŠ é€Ÿå™¨æ•°é‡éœ€è¦ä¸º2çš„æ•´æ•°å€ã€‚

å½“åç«¯å¯åŠ¨æˆåŠŸåï¼Œä¼šæ˜¾ç¤ºservice start at localhost:12222ï¼Œä¹‹åå¯åŠ¨å‰ç«¯ï¼š

```bash
python -m mi.frontend.launch --backend 12222 --server-port 13000
```

æ­¤æ—¶ä¼šåœ¨localhost:13000æš´éœ²æœ€ç»ˆçš„å¤§æ¨¡å‹æœåŠ¡ã€‚ç”¨æˆ·å¯é€šè¿‡å¦‚ä¸‹è¯­å¥è¿›è¡ŒæœåŠ¡è®¿é—®ï¼š

```bash
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
```

å¤§æ¨¡å‹æœåŠ¡APIçš„å…·ä½“å‚æ•°å’Œè®¿é—®æ–¹å¼å‚è€ƒç« èŠ‚ [qian-duan-fu-wu-api-jiao-hu-jie-kou-biao-zhun.md](api-documentation/qian-duan-fu-wu-api-jiao-hu-jie-kou-biao-zhun.md "mention")

## 0x03 æ¨¡å‹æœåŠ¡SDKåµŒå…¥å¼è°ƒç”¨

> æ­¤å¤„äº§å“ç­–ç•¥ä¸ºå°½å¯èƒ½å¤ç”¨æˆ–è€…é“¾æ¥å¼€æºç¤¾åŒºçš„æˆæœï¼Œæ¯”å¦‚openaiè‡ªå·±çš„sdkã€‚

## 0x04 å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿç»„ä»¶SDKä½¿ç”¨

> è¿™ä¸ªåŠŸèƒ½æ˜¯ä¸ºäº†è´´è¿‘æ¯”å¦‚tensorrt-llmæˆ–è€…vllmçš„ä½¿ç”¨æ–¹å¼ï¼Œéœ€è¦åˆ¤æ–­è¦ä¸è¦è¿›è¡Œè¿™ä¸ªå±‚çº§çš„æš´éœ²ã€‚
>
> tensorrt-llmæä¾›äº†ç”¨æˆ·å¯è‡ªç»„è£…çš„layerç»„ä»¶ï¼Œå¯ç”±ç”¨æˆ·æ¥è¿›è¡Œæ„å›¾ï¼Œå¯¹æ¨¡å‹è¿›è¡Œç²¾ç»†çš„æ§åˆ¶ï¼Œä¸»è¦åº”å¯¹åœºæ™¯æ˜¯ç”¨æˆ·æœ‰è‡ªå·±ç»“æ„çš„æ¨¡å‹æ—¶ã€‚
>
> vllmæ‰€æœ‰æºç å‡ä¸ºå¼€æºçŠ¶æ€ï¼Œæ–¹ä¾¿ç”¨æˆ·è¿›è¡Œå„æ–¹é¢çš„è‡ªæˆ‘è°ƒè¯•ã€‚
>
> ç›®å‰è€Œè¨€ï¼Œå»ºè®®ï¼šå¦‚æœç”¨æˆ·çœŸçš„æœ‰éœ€æ±‚å†è¿›è¡Œè¿™ä¸€æ¥å£çš„æš´éœ²ï¼Œè‡³å°‘ä¸æ˜¯å‰å‡ ä¸ªç‰ˆæœ¬çš„é‡ç‚¹ã€‚
>
> ç›®å‰å»ºè®®æš´éœ²çš„SDKæ¥å£ä¸ºï¼šmodelå±‚é¢çš„ä¸€äº›è¡Œä¸ºæ§åˆ¶ï¼Œæ¯”å¦‚generateæ¥å£ç­‰ç­‰ï¼Œç”¨äºç”¨æˆ·æ¥æ§åˆ¶ç²¾ç»†åŒ–çš„å¯åœèŠ‚å¥ï¼Œå¯¹é½vllmæˆ–è€…tensorrt-llmä¸­çš„æœåŠ¡åŒ–éƒ¨åˆ†çš„ç²¾ç»†æ§åˆ¶ã€‚

é™¤äº†å¯åŠ¨å‰ç«¯æœåŠ¡ä¹‹å¤–ï¼Œç”¨æˆ·è¿˜å¯ä»¥ç›´æ¥ä½¿ç”¨python SDKè¿›è¡Œæ¨¡å‹æ¨ç†ä»»åŠ¡ï¼Œç”¨äºè¿›è¡Œä¸šåŠ¡ä»£ç ç¼–ç¨‹ï¼Œæˆ–è¿›è¡Œä¸€äº›ç²¾ç»†åŒ–æ§åˆ¶ã€‚

ä»¥ä¸‹ä»£ç æ¡ˆä¾‹ç»™å‡ºäº†ä¸€ä¸ªæœ€ç®€çš„æ¨¡å‹æ¨ç†æ¡ˆä¾‹ï¼ˆæ³¨æ„ï¼šæ‰€æœ‰ä»¥ä¸‹æ¡ˆä¾‹å‡éœ€è¦é¦–å…ˆå¯åŠ¨åç«¯æœåŠ¡ï¼‰

```python
from mi import Model

model = Model(endpoint='http://localhost:12222')

inputs = [
    "hello, my name is",
    "Welcome to"
]

outputs = model.generate(inputs, do_sample=False, max_new_tokens=200)

# Print the outputs.
for output in outputs:
    prompt = model.tokenizer.decode(output.prompt_ids)
    complete_text = model.tokenizer.decode(output.ids)
    print(f"Prompt: {prompt!r}, complete text: {complete_text!r}")
```
